---
title: "FINAL PROJECT - STAT3106"
author: "Marlon Kegel"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(tidymodels)
library(haven)
library(visdat)
library(plm)
library(stringr)
library(corrplot)
library(cluster)     
library(factoextra) 
library(vip) 
library(igraph)
library(foreign)
library(MLmetrics)
```



## The data - GSS cumulative file (1972 - 2022)


#### demographic variables

```{r}

# link: https://drive.google.com/drive/folders/1EsKz48xpbvJ04dhPyC7hNQze-ANdl_el?usp=drive_link

setwd(
  "C:/Users/marlo/OneDrive/Desktop/Uni/S8/Applied Machine Learning (STAT3106)/final_project/demographic"
)

read.dct <- function(dct, labels.included = "yes") {
  temp <- readLines(dct)
  temp <- temp[grepl("_column", temp)]
  switch(labels.included, yes = {
    pattern <- "_column\\(([0-9]+)\\)\\s+([a-z0-9]+)\\s+(.*)\\s+%([0-9]+)[a-z]\\s+(.*)"
    classes <- c("numeric",
                 "character",
                 "character",
                 "numeric",
                 "character")
    N <- 5
    NAMES <- c("StartPos", "Str", "ColName", "ColWidth", "ColLabel")
  }, no = {
    pattern <- "_column\\(([0-9]+)\\)\\s+([a-z0-9]+)\\s+(.*)\\s+%([0-9]+).*"
    classes <- c("numeric", "character", "character", "numeric")
    N <- 4
    NAMES <- c("StartPos", "Str", "ColName", "ColWidth")
  })
  temp_metadata <- setNames(lapply(1:N, function(x) {
    out <- gsub(pattern, paste("\\", x, sep = ""), temp)
    out <- gsub("^\\s+|\\s+$", "", out)
    out <- gsub('\"', "", out, fixed = TRUE)
    class(out) <- classes[x]
    out
  }), NAMES)
  temp_metadata[["ColName"]] <- make.names(gsub("\\s", "", temp_metadata[["ColName"]]))
  temp_metadata
}

read.dat <- function(dat, metadata_var, labels.included = "yes") {
  read.table(dat, col.names = metadata_var[["ColName"]])
}

GSS_metadata <- read.dct("GSS.dct")
GSS_ascii <- read.dat("GSS.dat", GSS_metadata)
attr(GSS_ascii, "col.label") <- GSS_metadata[["ColLabel"]]
GSS_dem <- GSS_ascii

rm(GSS_ascii, GSS_metadata)

sum(apply(GSS_dem, 2, is.numeric)) - ncol(GSS_dem)

GSS_dem[GSS_dem <= -70] <- NA

sum(GSS_dem < 0, na.rm = TRUE)

GSS_dem <- GSS_dem %>% select(!c(MNTLHLTH, STRESS, MATESEX, PAIDSEX, SEXFREQ, BALLOT, CONINC, CONRINC, DEGREE, PADEG, MADEG, SPDEG, PHONE, PAPRES10))


# adding ethnicity variables

# link: https://drive.google.com/drive/folders/1cu107Drh9OarDbjWvXtgL4S-aXetExJ_?usp=drive_link

setwd(
"C:/Users/marlo/OneDrive/Desktop/Uni/S8/Applied Machine Learning (STAT3106)/final_project/ethnicity"
)

GSS_metadata <- read.dct("GSS.dct")
GSS_ascii <- read.dat("GSS.dat", GSS_metadata)
attr(GSS_ascii, "col.label") <- GSS_metadata[["ColLabel"]]
GSS_his <- GSS_ascii

rm(GSS_ascii, GSS_metadata)

sum(apply(GSS_his, 2, is.numeric)) - ncol(GSS_his)

GSS_his[GSS_his <= -70] <- NA

sum(GSS_his < 0, na.rm = TRUE)
GSS_his <- GSS_his %>% select(!c(BALLOT, ETHNIC))

GSS_dem <- full_join(GSS_dem, GSS_his, by = c("ID_", "YEAR"))

rm(GSS_his)

```



#### opinion variables

```{r}

#link: https://drive.google.com/drive/folders/13Gcx3lokcnMmLWtoA2oDTA6Vgh4Ns224?usp=drive_link

setwd(
  "C:/Users/marlo/OneDrive/Desktop/Uni/S8/Applied Machine Learning (STAT3106)/final_project/opinion"
)


GSS_metadata <- read.dct("GSS.dct")
GSS_ascii <- read.dat("GSS.dat", GSS_metadata)
attr(GSS_ascii, "col.label") <- GSS_metadata[["ColLabel"]]
GSS_opin <- GSS_ascii

rm(GSS_ascii, GSS_metadata)

sum(apply(GSS_opin, 2, is.numeric)) - ncol(GSS_opin)

GSS_opin[GSS_opin <= -70] <- NA

sum(GSS_opin < 0, na.rm = TRUE)

GSS_opin <- GSS_opin %>% select(!c(TAX, WRKEARN, WRKENJOY, BALLOT, ABSINGLE, PARTYID))

```



#### miscellaneous variables

```{r}

#link: https://drive.google.com/drive/folders/1lMWIfpj6drzzgfO_gleIxLs4dfBJbmhz?usp=drive_link

setwd(
 "C:/Users/marlo/OneDrive/Desktop/Uni/S8/Applied Machine Learning (STAT3106)/final_project/miscellaneous"
)


GSS_metadata <- read.dct("GSS.dct")
GSS_ascii <- read.dat("GSS.dat", GSS_metadata)
attr(GSS_ascii, "col.label") <- GSS_metadata[["ColLabel"]]
GSS_misc <- GSS_ascii

rm(GSS_ascii, GSS_metadata, read.dat, read.dct)

sum(apply(GSS_misc, 2, is.numeric)) - ncol(GSS_misc)

GSS_misc[GSS_misc <= -70] <- NA
subset_rows <- GSS_misc$NUMMEN > 700
GSS_misc$NUMMEN[subset_rows] <- NA

sum(GSS_misc < 0, na.rm = TRUE)

GSS_misc <- GSS_misc  %>%
  select(!c(BALLOT, HEALTH, FUND16, POLVIEWS))

```


## Cleaning

```{r}

na_column_dem <- data.frame(missing = colSums(is.na(GSS_dem)))
mean(na_column_dem$missing) / nrow(GSS_dem)

na_column_opin <- data.frame(missing = colSums(is.na(GSS_opin)))
mean(na_column_opin$missing) / nrow(GSS_opin)

na_column_misc <- data.frame(missing = colSums(is.na(GSS_misc)))
mean(na_column_misc$missing) / nrow(GSS_misc)

```



#### cleaning GSS_dem

```{r}

# removing variables with more than 80% NA
na_column_dem <- data.frame(missing = colSums(is.na(GSS_dem)))
na_column_dem$missing <- as.numeric(na_column_dem$missing)

columns_to_elim <- na_column_dem %>% filter(na_column_dem$missing >= 0.8 * nrow(GSS_dem))   
columns_to_elim <- row.names(columns_to_elim)
columns_to_elim <- as.character(columns_to_elim)
columns_to_keep <- setdiff(colnames(GSS_dem), columns_to_elim)
dem_clean <- GSS_dem %>% select(all_of(columns_to_keep))


# removing rows with NAs in the target feature
dem_clean <- dem_clean %>% filter(is.na(CLASS_) != T)

# removing rows with NA in more than 33% of columns
na_row_dem <- rowSums(is.na(dem_clean))

threshold <- ncol(dem_clean) * 0.33

dem_clean <- dem_clean[na_row_dem <= threshold, ]


# removing variables with more than 45% NA
na_column_dem <- data.frame(missing = colSums(is.na(dem_clean)))
na_column_dem$missing <- as.numeric(na_column_dem$missing)

columns_to_elim <- na_column_dem %>% filter(na_column_dem$missing >= 0.45 * nrow(dem_clean))   
columns_to_elim <- row.names(columns_to_elim)
columns_to_elim <- as.character(columns_to_elim)
columns_to_keep <- setdiff(colnames(dem_clean), columns_to_elim)
dem_clean <- dem_clean %>% select(all_of(columns_to_keep))

# removing rows with NA in more than 20% of columns
na_row_dem <- rowSums(is.na(dem_clean))

threshold <- ncol(dem_clean) * 0.2

dem_clean <- dem_clean[na_row_dem <= threshold, ]

``` 



#### cleaning GSS_opin

```{r}

# keeping only those observations that are in dem_clean
opin_clean <- semi_join(GSS_opin, dem_clean, by = c("YEAR", "ID_")) 

# removing variables with more than 51% NA
na_column_opin <- data.frame(missing = colSums(is.na(opin_clean)))
na_column_opin$missing <- as.numeric(na_column_opin$missing)

columns_to_elim <- na_column_opin %>% filter(na_column_opin$missing >= 0.51 * nrow(opin_clean))   
columns_to_elim <- row.names(columns_to_elim)
columns_to_elim <- as.character(columns_to_elim)
columns_to_keep <- setdiff(colnames(opin_clean), columns_to_elim)
opin_clean <- opin_clean %>% select(all_of(columns_to_keep))


# removing rows with NA in more than 30% of columns
na_row_opin <- rowSums(is.na(opin_clean))

threshold <- ncol(opin_clean) * 0.30

opin_clean <- opin_clean[na_row_opin <= threshold, ]


# removing variables with more than 25% NA
na_column_opin <- data.frame(missing = colSums(is.na(opin_clean)))
na_column_opin$missing <- as.numeric(na_column_opin$missing)

columns_to_elim <- na_column_opin %>% filter(na_column_opin$missing >= 0.25 * nrow(opin_clean))   
columns_to_elim <- row.names(columns_to_elim)
columns_to_elim <- as.character(columns_to_elim)
columns_to_keep <- setdiff(colnames(opin_clean), columns_to_elim)
opin_clean <- opin_clean %>% select(all_of(columns_to_keep))

# removing rows with NA in more than 20% of columns
na_row_opin <- rowSums(is.na(opin_clean))

threshold <- ncol(opin_clean) * 0.2

opin_clean <- opin_clean[na_row_opin <= threshold, ]


# join it back
dem_clean <- semi_join(dem_clean, opin_clean, by = c("YEAR", "ID_")) 

``` 



#### cleaning GSS_misc

```{r}

# keeping only those observations that are in dem_clean

misc_clean <- semi_join(GSS_misc, dem_clean, by = c("YEAR", "ID_")) 

# removing variables with more than 20% NA
na_column_misc <- data.frame(missing = colSums(is.na(misc_clean)))
na_column_misc$missing <- as.numeric(na_column_misc$missing)

columns_to_elim <- na_column_misc %>% filter(na_column_misc$missing >= 0.2 * nrow(misc_clean))   
columns_to_elim <- rownames(columns_to_elim)
columns_to_elim <- as.character(columns_to_elim)
columns_to_keep <- setdiff(colnames(misc_clean), columns_to_elim)
misc_clean <- misc_clean %>% select(all_of(columns_to_keep))


# removing rows with NA in more than 20% of columns
na_row_misc <- rowSums(is.na(misc_clean))

threshold <- ncol(misc_clean) * 0.2

misc_clean <- misc_clean[na_row_misc <= threshold, ]


# join it back
dem_clean <- semi_join(dem_clean, misc_clean, by = c("YEAR", "ID_")) 
opin_clean <- semi_join(opin_clean, misc_clean, by = c("YEAR", "ID_")) 

```

```{r}
# removing rows with NA in more than 10% of columns
na_row_dem <- rowSums(is.na(dem_clean))

threshold <- ncol(dem_clean) * 0.10

dem_clean <- dem_clean[na_row_dem <= threshold, ]

opin_clean <- semi_join(opin_clean, dem_clean, by = c("YEAR", "ID_")) 
misc_clean <- semi_join(misc_clean, dem_clean, by = c("YEAR", "ID_")) 


# joining into all variable dataset 
columns <- colnames(dem_clean)
columns <- c(columns, colnames(opin_clean))
columns <- c(columns, colnames(misc_clean))
columns <- unique(columns)

all_clean <- left_join(dem_clean, opin_clean, by = c("YEAR", "ID_", "CLASS_"))
all_clean <- left_join(all_clean, misc_clean, by = c("YEAR", "ID_", "CLASS_")) 

setdiff(colnames(all_clean), columns)
setdiff(columns, colnames(all_clean))

# removing variables with more than 25% overall NA
na_column_all <- data.frame(missing = colSums(is.na(all_clean)))
na_column_all$missing <- as.numeric(na_column_all$missing)

columns_to_elim <- na_column_all %>% filter(na_column_all$missing >= 0.25 * nrow(all_clean))   
columns_to_elim <- rownames(columns_to_elim)
columns_to_elim <- as.character(columns_to_elim)
columns_to_keep <- setdiff(colnames(all_clean), columns_to_elim)
all_clean <- all_clean %>% select(all_of(columns_to_keep))

# removing rows with NA in more than 10% of all columns
na_row_all <- rowSums(is.na(all_clean))

threshold <- ncol(all_clean) * 0.10

all_clean <- all_clean[na_row_all <= threshold, ]

```


#### Initial PRE-PROCESSING

```{r}

columns_dem <- intersect(colnames(dem_clean), colnames(all_clean))
columns_opin <- intersect(colnames(opin_clean), colnames(all_clean))
columns_misc <- intersect(colnames(misc_clean), colnames(all_clean))

binary_cols <- sapply(all_clean, function(x) length(unique(na.omit(x))) == 2)
binary_cols <- names(binary_cols[binary_cols])

unique(sapply(all_clean[,binary_cols], unique))

onetwo_cols <- sapply(all_clean, function(x) all(na.omit(x) %in% c(1, 2)))
onetwo_cols <- names(onetwo_cols[onetwo_cols])
onetwo_cols

all_clean <- all_clean %>% mutate(across(all_of(onetwo_cols), ~ 2 - .x))

fourfive_cols <- sapply(all_clean, function(x) all(na.omit(x) %in% c(4, 5)))
fourfive_cols <- names(fourfive_cols[fourfive_cols])
fourfive_cols

all_clean <- all_clean %>% mutate(across(all_of(fourfive_cols), ~ 5 - .x))

threefour_cols <- sapply(all_clean, function(x) all(na.omit(x) %in% c(3, 4)))
threefour_cols <- names(threefour_cols[threefour_cols])
threefour_cols

all_clean <- all_clean %>% mutate(across(all_of(threefour_cols), ~ 4 - .x))

all_clean <- all_clean %>%
  mutate(across(all_of(binary_cols), as.integer))

factor_candidates <- sapply(all_clean, function(x) length(unique(na.omit(x))) < 5)
factor_candidates <- names(factor_candidates[factor_candidates])
factor_candidates <- setdiff(factor_candidates, binary_cols)

all_clean <- all_clean %>%
  mutate(across(all_of(c(factor_candidates, "WRKSTAT", "OCC10", "INDUS10", "SPWRKSTA", "SPOCC10", "SPIND10", "PAOCC10", "RES16", "REG16", "FAMILY16", "PARBORN", "GRANBORN", "REGION", "RELIG", "RELIG16", "SPREL", "PHONE", "ID_", "PARTYID", "ETH1")), as.character))

all_clean <- all_clean %>%
  mutate(across(all_of(c(factor_candidates, "WRKSTAT", "OCC10", "INDUS10", "SPWRKSTA", "SPOCC10", "SPIND10", "PAOCC10", "RES16", "REG16", "FAMILY16", "PARBORN", "GRANBORN", "REGION", "RELIG", "RELIG16", "SPREL", "PHONE", "ID_", "PARTYID", "ETH1")), factor))

all_clean <- all_clean %>% mutate(OCC10 = as.factor(substr(as.character(OCC10), 1, 2)), 
                                  PAOCC10 = as.factor(substr(as.character(PAOCC10), 1, 2)), 
                                  SPOCC10 = as.factor(substr(as.character(SPOCC10), 1, 2)), 
                                  INDUS10 = as.factor(substr(as.character(SPOCC10), 1, 2)),
                                  SPIND10 = as.factor(substr(as.character(SPOCC10), 1, 2)))

all_clean <- all_clean %>% filter(is.na(CLASS_) != T)
all_clean <- all_clean %>% filter(YEAR < 2020)

dem_clean <- all_clean %>% select(all_of(columns_dem))
opin_clean <- all_clean %>% select(all_of(columns_opin))
misc_clean <- all_clean %>% select(all_of(columns_misc))

```


```{r}
na_column_dem <- data.frame(missing = colSums(is.na(dem_clean)))
mean(na_column_dem$missing) / nrow(dem_clean)

na_column_opin <- data.frame(missing = colSums(is.na(opin_clean)))
mean(na_column_opin$missing) / nrow(opin_clean)

na_column_misc <- data.frame(missing = colSums(is.na(misc_clean)))
mean(na_column_misc$missing) / nrow(misc_clean)

na_column_all <- data.frame(missing = colSums(is.na(all_clean)))
mean(na_column_all$missing) / nrow(all_clean)

```


#### Exploratory Data Analysis

```{r}

length(levels(all_clean$ETH1))
length(levels(all_clean$OCC10))
length(levels(all_clean$SPOCC10))

sum(is.na(all_clean)) / length(unlist(all_clean))
na_by_col <- 100*(colSums(is.na(all_clean)) / nrow(all_clean))
na_by_col[na_by_col > 10]

na_count_per_row <- rowSums(is.na(all_clean))
na_count_per_row <- as.factor(na_count_per_row)
summary(na_count_per_row)

dem1 <- dem_clean %>% select(1:21)
dem2 <- dem_clean %>% select(22:43)
dem3 <- dem_clean %>% select(44:64)
vis_dat(dem1)
vis_dat(dem2)
vis_dat(dem3)


opin1 <- opin_clean %>% select(1:21)
opin2 <- opin_clean %>% select(22:43)
opin3 <- opin_clean %>% select(44:65)
vis_dat(opin1)
vis_dat(opin2)
vis_dat(opin3)

vis_dat(misc_clean)

nearZeroVar(all_clean)

```


```{r}

numeric <- sapply(dem_clean, is.numeric)
numeric <- numeric[numeric == T]
numeric <- names(numeric)

cor_matrix <- cor(dem_clean[, numeric], use = "pairwise.complete.obs")

cor_matrix <- as.data.frame(cor_matrix)

condition_met <- cor_matrix > 0.6 | cor_matrix < -0.6
rows_to_keep <- rowSums(condition_met, na.rm = T) != 1
cor_matrix <- cor_matrix[rows_to_keep, ]
cols_to_keep <- colSums(condition_met, na.rm = T) != 1
cor_matrix <- cor_matrix[, cols_to_keep]

cor_matrix <- as.matrix(cor_matrix)

corrplot(cor_matrix, 
         method = "color", 
         type = "upper",
         order = "hclust",  # Order variables based on hierarchical clustering
         tl.col = "black",  # Color of text labels
         tl.srt = 45,  # Rotation of text labels
         addCoef.col = "black")  # Add coefficient colors

# after this step we removed the variables CONINC (kept REALINC), CONRINC (kept REALRINC), ETHNIC (and kept ETH1), DEGREE (and kept EDUC),  PADEG (keeping PAEDUC), MADEG (kept MAEDUC), SPDEG (kept SPEDUC), PAPRES10 (keeping PASEI)

numeric <- sapply(opin_clean, is.numeric)
numeric <- numeric[numeric == T]
numeric <- names(numeric)

cor_matrix <- cor(opin_clean[, numeric], use = "pairwise.complete.obs")

cor_matrix <- as.data.frame(cor_matrix)

condition_met <- cor_matrix > 0.6 | cor_matrix < -0.6
rows_to_keep <- rowSums(condition_met) != 1
cor_matrix <- cor_matrix[rows_to_keep, ]
cols_to_keep <- colSums(condition_met) != 1
cor_matrix <- cor_matrix[, cols_to_keep]

cor_matrix <- as.matrix(cor_matrix)

corrplot(cor_matrix, 
         method = "color", 
         type = "upper",
         order = "hclust",  # Order variables based on hierarchical clustering
         tl.col = "black",  # Color of text labels
         tl.srt = 45,  # Rotation of text labels
         addCoef.col = "black")  # Add coefficient colors

# after this step we removed ABSINGLE (keeping ABPOOR)


numeric <- sapply(misc_clean, is.numeric)
numeric <- numeric[numeric == T]
numeric <- names(numeric)

cor_matrix <- cor(misc_clean[, numeric], use = "pairwise.complete.obs")

corrplot(cor_matrix, 
         method = "color", 
         type = "upper",
         order = "hclust",  # Order variables based on hierarchical clustering
         tl.col = "black",  # Color of text labels
         tl.srt = 45,  # Rotation of text labels
         addCoef.col = "black")  # Add coefficient colors

# 

numeric <- sapply(all_clean, is.numeric)
numeric <- numeric[numeric == T]
numeric <- names(numeric)

cor_matrix <- cor(all_clean[, numeric], use = "pairwise.complete.obs")

cor_matrix <- as.data.frame(cor_matrix)

condition_met <- cor_matrix > 0.7 | cor_matrix < -0.7
rows_to_keep <- rowSums(condition_met, na.rm = T) != 1
cor_matrix <- cor_matrix[rows_to_keep, ]
cols_to_keep <- colSums(condition_met, na.rm = T) != 1
cor_matrix <- cor_matrix[, cols_to_keep]

cor_matrix <- as.matrix(cor_matrix)

corrplot(cor_matrix, 
         method = "color", 
         type = "upper",
         order = "hclust",  # Order variables based on hierarchical clustering
         tl.col = "black",  # Color of text labels
         tl.srt = 45,  # Rotation of text labels
         addCoef.col = "black")  # Add coefficient colors

```

```{r}

par(mfrow = c(2, 3))
hist(all_clean$REALINC, breaks = 20)
hist(all_clean$EDUC, breaks = 20)
hist(all_clean$PRESTG10, breaks = 20)
hist(all_clean$REALRINC, breaks = 30)
hist(all_clean$AGE, breaks = 20)
hist(all_clean$HRS1, breaks = 20)

```


```{r}

frequency <- data.frame(class_id = all_clean$CLASS_, year = all_clean$YEAR)
frequency <- frequency %>% mutate(class_id = case_when(
  class_id == 1 ~ "Lower Class", 
  class_id == 2 ~ "Working Class",
  class_id == 3 ~ "Middle Class",
  class_id == 4 ~ "Upper Class",
))

frequency$decade <- paste0(((frequency$year %/% 10) * 10), "s")
frequency$decade <- as.factor(frequency$decade)

frequency$class_id <- factor(frequency$class_id, ordered = T, levels = c("Lower Class", "Working Class", "Middle Class", "Upper Class"))
frequency <- na.omit(frequency)

frequency <- frequency %>%
  group_by(decade, class_id) %>%
  summarise(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)

decade_n <- frequency %>%
  group_by(decade) %>%
  summarise(n = sum(count)) 

frequency <- frequency %>%
  left_join(decade_n, by = "decade")

class_id_plot <- ggplot(frequency, aes(x = class_id, y = count, fill = class_id)) +
  geom_col() +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    vjust = -0.5,
    position = position_dodge(width = 0.9),
    color = "black"
  ) +
  scale_fill_manual(
    values = c(
      "Lower Class" = "lightblue1",
      "Working Class" = "navajowhite",
      "Middle Class" = "aquamarine",
      "Upper Class" = "mistyrose2"
    )
  ) +
  ggtitle("Subjective Class Identification") +
  ylab("Frequency") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title.x = element_blank(),
    legend.position = "none"
  )

class_id_plot +
  facet_wrap(~ decade) +
  geom_text(data = decade_n, aes(x = 4, y = 900, label = paste("n =", n)), 
            inherit.aes = FALSE, check_overlap = TRUE, color = "grey50", size = 3)

```


```{r}

frequency <- data.frame(race = all_clean$RACE, year = all_clean$YEAR)
frequency <- frequency %>% mutate(race = case_when(
  race == 1 ~ "White", 
  race == 2 ~ "Black",
  race == 3 ~ "Other"
))

frequency$decade <- paste0(((frequency$year %/% 10) * 10), "s")
frequency$decade <- as.factor(frequency$decade)

frequency$race <- factor(frequency$race, ordered = T, levels = c("White", "Black", "Other"))
frequency <- na.omit(frequency)

frequency <- frequency %>%
  group_by(decade, race) %>%
  summarise(count = n()) %>%
  mutate(percentage = count / sum(count) * 100)

decade_n <- frequency %>%
  group_by(decade) %>%
  summarise(n = sum(count)) 

frequency <- frequency %>%
  left_join(decade_n, by = "decade")

racial_comp_plot <- ggplot(frequency, aes(x = race, y = count, fill = race)) +
  geom_col() +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    vjust = -0.2,
    position = position_dodge(width = 0.9),
    color = "black"
  ) +
  scale_fill_manual(
    values = c(
      "White" = "lightblue1",
      "Black" = "mistyrose2",
      "Other" = "aquamarine"
    )
  ) +
  ggtitle("Racial Composition") +
  ylab("Frequency") +
   coord_cartesian(ylim = c(0, 1500)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title.x = element_blank(),
    legend.position = "none"
  )

racial_comp_plot +
  facet_wrap(~ decade) +
  geom_text(data = decade_n, aes(x = 3.3, y = 1370, label = paste("n =", n)), 
            inherit.aes = FALSE, check_overlap = TRUE, color = "grey50", size = 3)

```


```{r}
eth1 <- as.data.frame(summary(all_clean$ETH1))
colnames(eth1) <- c("count")

eth1 %>%
  arrange(desc(count)) %>%
  slice_head(n = 16)

frequency <- data.frame(ethnic = all_clean$ETH1)
frequency <- frequency %>% mutate(ethnic = case_when(
  ethnic == 11 ~ "German", 
  ethnic == 8 ~ "English",
  ethnic == 14 ~ "Irish",
  ethnic == 15 ~ "Italian",
  ethnic == 1 ~ "African",
  ethnic == 24 ~ "Scots",
  ethnic == 17 ~ "Mexican",
  ethnic == 30 ~ "NativeAm",
  ethnic == 10 ~ "French",
  ethnic == 21 ~ "Polish",
  ethnic == 23 ~ "Russian",
  ethnic == 26 ~ "Swede",
  ethnic == 19 ~ "Norweg",
  ethnic == 18 ~ "Dutch",
  is.na(ethnic) ~ NA,
  T ~ "Other"
))

frequency$ethnic <- factor(frequency$ethnic, ordered = T, levels = c("German", "English / Welsh", "Irish", "Italian", "African", "Mexican", "Scots", "NativeAm", "French", "Polish", "Norweg", "Swede", "Russian", "Dutch", "Other"))
frequency <- na.omit(frequency)

frequency <- frequency %>%
  group_by(ethnic) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  mutate(percentage = count / sum(count) * 100)

ethnic_comp_plot <- ggplot(frequency, aes(x = ethnic, y = count)) +
  geom_col(colour = "grey90", fill = "grey40", alpha = 0.9) +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    vjust = -0.5,
    position = position_dodge(width = 0.9),
    color = "black"
  ) +
  ggtitle("Family Origin / Ethnic background") +
  ylab("Frequency") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title.x = element_blank(),
    legend.position = "none"
  )

ethnic_comp_plot

```


```{r}

year <- ggplot(all_clean, aes(x = YEAR)) +
  geom_histogram(
    binwidth = 2,
    na.rm = T,
    colour = "grey50",
    fill = "mistyrose2", 
    alpha = 0.9
  ) +
  ggtitle("Year of Interview") +
  scale_x_continuous(breaks = c(seq(1985, 2020, by = 5))) +
  coord_cartesian(xlim = c(1983, 2019)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), axis.title.x = element_blank())

year

```


### DATA SPLITTING

```{r}
remove <- ls()
remove <- remove[!remove %in% c("all_clean", "dem_clean", "opin_clean", "misc_clean", "columns_dem", "columns_opin", "columns_misc", "columns")]
rm(list = remove)


levels(all_clean$CLASS_) <- c("L1", "L2", "L3", "L4")

all_clean <- all_clean %>% relocate(all_of(columns_dem), .before = everything()) %>% relocate(all_of(columns_opin), .after = tail(columns_dem, n=1)) %>% relocate(all_of(columns_misc), .after = tail(columns_opin, n=1)) %>% relocate(all_of(c("ID_", "YEAR", "CLASS_")), .before = everything())

set.seed(1)
split <- initial_split(all_clean, prop = 0.7, strata = "CLASS_")
all_train <- training(split)
all_test <- testing(split)

```


### Pre-Processing

##### all vars

```{r}

blueprint <- recipe(CLASS_ ~ ., data = all_train) %>%
  
  step_string2factor(all_nominal_predictors()) %>%
  
  step_nzv(all_predictors()) %>%
  
  step_impute_knn(all_predictors()) %>%
  
  step_other(all_nominal_predictors(),
             threshold = 0.01,
             other = "Other") %>%
  
  step_center(all_numeric_predictors()) %>%
  
  step_scale(all_numeric_predictors()) %>%
  
  step_dummy(all_nominal_predictors()) %>%
  
  step_nzv(all_predictors(), freq_cut = 30, unique_cut = 20)


blueprint_prep <- prep(blueprint, training = all_train)
train <- bake(blueprint_prep, new_data = all_train)
test <- bake(blueprint_prep, new_data = all_test)

```


#### demographic vars

```{r}

dem_train <- all_train %>% select(all_of(columns_dem))
dem_test <- all_test %>% select(all_of(columns_dem))

blueprint <- recipe(CLASS_ ~ ., data = dem_train) %>%
  
  step_string2factor(all_nominal_predictors()) %>%
  
  step_nzv(all_predictors()) %>%
  
  step_impute_knn(all_predictors()) %>%
  
  step_other(all_nominal_predictors(),
             threshold = 0.01,
             other = "Other") %>%
  
  step_center(all_numeric_predictors()) %>%
  
  step_scale(all_numeric_predictors()) %>%
  
  step_dummy(all_nominal_predictors()) %>%
  
  step_nzv(all_predictors(), freq_cut = 30, unique_cut = 20)


blueprint_prep <- prep(blueprint, training = dem_train)
dem_train <- bake(blueprint_prep, new_data = dem_train)
dem_test <- bake(blueprint_prep, new_data = dem_test)
```


#### opin vars

```{r}

opin_train <- all_train %>% select(all_of(columns_opin))
opin_test <- all_test %>% select(all_of(columns_opin))

blueprint <- recipe(CLASS_ ~ ., data = opin_train) %>%
  
  step_string2factor(all_nominal_predictors()) %>%
  
  step_nzv(all_predictors()) %>%
  
  step_impute_knn(all_predictors()) %>%
  
  step_other(all_nominal_predictors(),
             threshold = 0.01,
             other = "Other") %>%
  
  step_center(all_numeric_predictors()) %>%
  
  step_scale(all_numeric_predictors()) %>%
  
  step_dummy(all_nominal_predictors()) %>%
  
  step_nzv(all_predictors(), freq_cut = 30, unique_cut = 20)


blueprint_prep <- prep(blueprint, training = opin_train)
opin_train <- bake(blueprint_prep, new_data = opin_train)
opin_test <- bake(blueprint_prep, new_data = opin_test)
```


#### miscellaneous vars

```{r}

misc_train <- all_train %>% select(all_of(columns_misc))
misc_test <- all_test %>% select(all_of(columns_misc))

blueprint <- recipe(CLASS_ ~ ., data = misc_train) %>%
  
  step_string2factor(all_nominal_predictors()) %>%
  
  step_nzv(all_predictors()) %>%
  
  step_impute_knn(all_predictors()) %>%
  
  step_other(all_nominal_predictors(),
             threshold = 0.01,
             other = "Other") %>%
  
  step_center(all_numeric_predictors()) %>%
  
  step_scale(all_numeric_predictors()) %>%
  
  step_dummy(all_nominal_predictors()) %>%
  
  step_nzv(all_predictors(), freq_cut = 30, unique_cut = 20)


blueprint_prep <- prep(blueprint, training = misc_train)
misc_train <- bake(blueprint_prep, new_data = misc_train)
misc_test <- bake(blueprint_prep, new_data = misc_test)
```



## XG BOOST


#### demographic variables

```{r, warning=FALSE}
resample <- trainControl(method = "cv",
                         number = 5,
                         classProbs = TRUE,
                         summaryFunction = multiClassSummary) 

hyper_grid <- expand.grid(nrounds = c(100, 150),   
                          max_depth = c(4, 6), 
                          eta = c(0.05, 0.1),    
                          min_child_weight = c(5, 10), 
                          subsample = c(0.4, 0.6), 
                          gamma = 0,
                          colsample_bytree = 1)
set.seed(1)

suppressWarnings(
  xg_fit <- train(
    CLASS_ ~ .,
    data = dem_train,
    method = "xgbTree",
    verbose = FALSE,
    trControl = resample,
    tuneGrid = hyper_grid,
    metric = "ROC"
  )
)

xg_fit

plot(xg_fit)
```

```{r}
xg_control_final <- trainControl(method = "none", classProbs = TRUE)

xg_final_fit <- train(CLASS_ ~ .,
                data = dem_train, 
                method = "xgbTree",
                verbose = FALSE,
                trControl = xg_control_final, 
                tuneGrid = data.frame(nrounds = 150,    
                          max_depth = 4,   
                          eta = 0.05,   
                          min_child_weight = 10,
                          subsample = 0.4,  
                          gamma = 0,
                          colsample_bytree = 1),
                metric = "ROC", 
                importance = "impurity")


# Training set results

xg_pred_train <- predict(xg_final_fit, newdata = dem_train)

xg_train_results <- confusionMatrix(dem_train$CLASS_, xg_pred_train)

xg_train_results


# Test set results

xg_pred_test <- predict(xg_final_fit, newdata = dem_test)

xg_test_results <- confusionMatrix(dem_test$CLASS_, xg_pred_test)

xg_test_results


# Feature importance

vip(xg_final_fit, num_features = 20)

```


#### opinion variables

```{r, warning=FALSE}
resample <- trainControl(method = "cv",
                         number = 5,
                         classProbs = TRUE,
                         summaryFunction = multiClassSummary) 

hyper_grid <- expand.grid(nrounds = c(100, 150),   
                          max_depth = c(4, 6), 
                          eta = c(0.05, 0.1),    
                          min_child_weight = c(5, 10), 
                          subsample = c(0.4, 0.6), 
                          gamma = 0,
                          colsample_bytree = 1)
set.seed(1)

suppressWarnings(
  xg_fit <- train(
    CLASS_ ~ .,
    data = opin_train,
    method = "xgbTree",
    verbose = FALSE,
    trControl = resample,
    tuneGrid = hyper_grid,
    metric = "ROC"
  )
)

xg_fit

plot(xg_fit)
```


```{r}
xg_control_final <- trainControl(method = "none", classProbs = TRUE)

xg_final_fit <- train(CLASS_ ~ .,
                data = opin_train, 
                method = "xgbTree",
                verbose = FALSE,
                trControl = xg_control_final, 
                tuneGrid = data.frame(nrounds = 150,    
                          max_depth = 4,   
                          eta = 0.05,   
                          min_child_weight = 10,
                          subsample = 0.6,  
                          gamma = 0,
                          colsample_bytree = 1),
                metric = "ROC", 
                importance = "impurity")


# Training set results

xg_pred_train <- predict(xg_final_fit, newdata = opin_train)

xg_train_results <- confusionMatrix(opin_train$CLASS_, xg_pred_train)

xg_train_results


# Test set results

xg_pred_test <- predict(xg_final_fit, newdata = opin_test)

xg_test_results <- confusionMatrix(opin_test$CLASS_, xg_pred_test)

xg_test_results


# Feature importance

vip(xg_final_fit, num_features = 20)
```


#### all variables 

```{r, warning=FALSE}
resample <- trainControl(method = "cv",
                         number = 5,
                         classProbs = TRUE,
                         summaryFunction = multiClassSummary) 

hyper_grid <- expand.grid(nrounds = c(100, 150),   
                          max_depth = c(4, 6), 
                          eta = c(0.05, 0.1),    
                          min_child_weight = c(5, 10), 
                          subsample = c(0.4, 0.6), 
                          gamma = 0,
                          colsample_bytree = 1)
set.seed(1)

suppressWarnings(
  xg_fit <- train(
    CLASS_ ~ .,
    data = train,
    method = "xgbTree",
    verbose = FALSE,
    trControl = resample,
    tuneGrid = hyper_grid,
    metric = "ROC"
  )
)

xg_fit

plot(xg_fit)
```


```{r}
xg_control_final <- trainControl(method = "none", classProbs = TRUE)

xg_final_fit <- train(CLASS_ ~ .,
                data = train, 
                method = "xgbTree",
                verbose = FALSE,
                trControl = xg_control_final, 
                tuneGrid = data.frame(nrounds = 150,    
                          max_depth = 4,   
                          eta = 0.05,   
                          min_child_weight = 5,
                          subsample = 0.6,  
                          gamma = 0,
                          colsample_bytree = 1),
                metric = "ROC", 
                importance = "impurity")


# Training set results

xg_pred_train <- predict(xg_final_fit, newdata = train)

xg_train_results <- confusionMatrix(train$CLASS_, xg_pred_train)

xg_train_results


# Test set results

xg_pred_test <- predict(xg_final_fit, newdata = test)

xg_test_results <- confusionMatrix(test$CLASS_, xg_pred_test)

xg_test_results


# Feature importance

vip(xg_final_fit, num_features = 20)
```


## RANDOM FOREST 

#### demographic variables

```{r}
rf_resamp <- trainControl(method = "boot", number = 5, classProbs = TRUE, summaryFunction = multiClassSummary)
hyper_grid <- expand.grid(mtry = c(13, 15, 17),
                          splitrule = c("gini", "extratrees"),
                          min.node.size = c(5, 7, 9)) 


set.seed(1)

rf_fit <- train(CLASS_ ~ .,
                data = dem_train, 
                method = "ranger",
                verbose = FALSE,
                trControl = rf_resamp, 
                tuneGrid = hyper_grid,
                metric = "ROC")
rf_fit
plot(rf_fit)

```

```{r}
rf_fit_final <- trainControl(method = "none", classProbs = TRUE)

rf_final <- train(CLASS_ ~., 
                  
                  data = dem_train,
                  
                  method = "ranger",
                  
                  trControl = rf_fit_final,
                  
                  metric = "ROC",
                  
                  tuneGrid = data.frame(.mtry = 17,
                                        
                                        .min.node.size = 7,
                                        
                                        .splitrule = "gini"), 
                  
                  importance = "impurity")

# Training set results

rf_pred_train <- predict(rf_final, newdata = dem_train)

rf_train_results <- confusionMatrix(dem_train$CLASS_, rf_pred_train)

rf_train_results

# Test set results

rf_pred_test <- predict(rf_final, newdata = dem_test)

rf_test_results <- confusionMatrix(dem_test$CLASS_, rf_pred_test)

rf_test_results


# Feature importance

vip(rf_final, num_features = 20)
```


#### opinion variables

```{r}
rf_resamp <- trainControl(method = "boot", number = 5, classProbs = TRUE, summaryFunction = multiClassSummary)
hyper_grid <- expand.grid(mtry = c(13, 15, 17),
                          splitrule = c("gini", "extratrees"),
                          min.node.size = c(5, 7, 9)) 


set.seed(1)

rf_fit <- train(CLASS_ ~ .,
                data = opin_train, 
                method = "ranger",
                verbose = FALSE,
                trControl = rf_resamp, 
                tuneGrid = hyper_grid,
                metric = "ROC")
rf_fit
plot(rf_fit)

```


```{r}
rf_fit_final <- trainControl(method = "none", classProbs = TRUE)

rf_final <- train(CLASS_ ~., 
                  
                  data = opin_train,
                  
                  method = "ranger",
                  
                  trControl = rf_fit_final,
                  
                  metric = "ROC",
                  
                  tuneGrid = data.frame(.mtry = 13,
                                        
                                        .min.node.size = 7,
                                        
                                        .splitrule = "gini"), 
                  
                  importance = "impurity")


# Training set results

rf_pred_train <- predict(rf_final, newdata = opin_train)

rf_train_results <- confusionMatrix(opin_train$CLASS_, rf_pred_train)

rf_train_results


# Test set results

rf_pred_test <- predict(rf_final, newdata = opin_test)

rf_test_results <- confusionMatrix(opin_test$CLASS_, rf_pred_test)

rf_test_results


# Feature importance

vip(rf_final, num_features = 20)
```


#### all variables

```{r}
rf_resamp <- trainControl(method = "boot", number = 5, classProbs = TRUE, summaryFunction = multiClassSummary)
hyper_grid <- expand.grid(mtry = c(13, 15, 17),
                          splitrule = c("gini", "extratrees"),
                          min.node.size = c(5, 7, 9)) 


set.seed(1)

rf_fit <- train(CLASS_ ~ .,
                data = train, 
                method = "ranger",
                verbose = FALSE,
                trControl = rf_resamp, 
                tuneGrid = hyper_grid,
                metric = "ROC")
rf_fit
plot(rf_fit)

```


```{r}
rf_fit_final <- trainControl(method = "none", classProbs = TRUE)

rf_final <- train(CLASS_ ~., 
                  
                  data = train,
                  
                  method = "ranger",
                  
                  trControl = rf_fit_final,
                  
                  metric = "ROC",
                  
                  tuneGrid = data.frame(.mtry = 17,
                                        
                                        .min.node.size = 7,
                                        
                                        .splitrule = "gini"), 
                  
                  importance = "impurity")

# Training set results

rf_pred_train <- predict(rf_final, newdata = train)

rf_train_results <- confusionMatrix(train$CLASS_, rf_pred_train)

rf_train_results

# Test set results

rf_pred_test <- predict(rf_final, newdata = test)

rf_test_results <- confusionMatrix(test$CLASS_, rf_pred_test)

rf_test_results


# Feature importance

vip(rf_final, num_features = 20)

```




### ARTIFICIAL NEURAL NETWORK

```{r}
set.seed(1)
resample <- trainControl(method = "cv",
                        number = 5,
                        classProbs = TRUE,
                        summaryFunction = multiClassSummary)

hyper_grid <- expand.grid(layer1 = c(25, 45),
                          layer2 = c(0, 30),
                          layer3 = c(0, 15))
dnn_fit <- train(CLASS_ ~ .,
                data = dem_train,
                method = "mlpML",
                trControl = resample,
                tuneGrid = hyper_grid,
                metric = "ROC")
dnn_fit

```

```{r}
dnn_final <- train(CLASS_ ~ .,
                  data = dem_train,
                  method = "mlpML",
                  tuneGrid = data.frame(layer1 = 25, layer2 = 0, layer3 = 0),
                  metric = "ROC",
                  trControl = trainControl(method = "none", classProbs = TRUE))

dnn_pred_train <- predict(dnn_final, newdata = dem_train)
dnn_pred_test <- predict(dnn_final, newdata = dem_test)

print(confusionMatrix(dnn_pred_train, dem_train$CLASS_))
print(confusionMatrix(dnn_pred_test, dem_test$CLASS_))
```